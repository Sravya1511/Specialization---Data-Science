#there are 3 Categorical and 2 numeric variables
head(Arthritis)
head(Arthritis, 10)
tail(Arthritis)
#Gives the structure of the data set - like distinct categories - found in levles
str(Arthritis)
install.packages("DataExplorer")
library(DataExplorer)
plot_str(Arthritis)
#Gives 1 to 17 rows
Arthritis[1:17,]
#Gives the mean meadian for numeric data
#Gives the number of each observation in the categorical data
summary(Arthritis)
#Gives the information about the missing column count.
introduce(Arthritis)
#Gives if the values are null or not
is.na(Arthritis)
is.na(Arthritis$ID)
plot_missing(Arthritis)
#To see number of levels in the column
Arthritis$Improved
length(Arthritis$Improved)
table((Arthritis$Improved))
summary(Arthritis$Improved)
#Gives the proportion of the discrete variable in a particular column
tab1 = table((Arthritis$Improved))
prop.table(tab1)
#How many male and female are treated as (Placebo or treated)
library(epiR)
tab2 = xtabs(~ Sex + Treatment, Arthritis)
tab2
#Gives the plot for categorical varibles
plot_bar(Arthritis)
plot_bar(Arthritis$Treatment)
#Gives the plot for numeric variables
plot_histogram(Arthritis)
#plot_boxplot(Arthritis$Age)
plot_bar(Arthritis)
plot_histogram(Arthritis)
#Age vector
age = c(25, 35, 50)
#Salary Vector
salary = c(200000, 1200000, 2000000)
#Create a data frame
df = data.frame("Age" = age, "Salary" = salary, stringsAsFactors = FALSE)
df
#mean
result.mean = mean(df$Salary)
result.mean
#Min - Max Normalization
#write normalization function
normalize = function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
#Applying normalizayion to all the data
dfNorm = as.data.frame(lapply(df, normalize))
dfNorm
#apply between 1 to 2 rows
dfNorm1 = as.data.frame(lapply(df[1:2], normalize))
dfNorm1
#Z-score standardization
dfNormZ = as.data.frame(scale(df[1:2]))
dfNormZ
#Z-score standardization
dfNormZ = as.data.frame(scale(df[1:2]))
dfNormZ
stock = read.csv("Stock_Index_table.csv",header = FALSE)
stock = read.csv("Stock_Index_table.csv",header = FALSE)
#4)a)Read in the data in R using data<-read.csv("myfirstdata.csv",header=FALSE). Note, you first need to specify your working directory using the setwd() command. Determine whether each of the two attributes (columns) is treated as qualitative (categorical) or quantitative (numeric) using R. Explain how you can tell using R.
firstdata = read.csv("myfirstdata.csv",header = FALSE)
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam")
stock = read.csv("Stock_Index_table.csv",header = FALSE)
str(stock)
summary(stock)
stock$diffV2 <- c(0, diff(stock$V1))
summary(stock)
stock$diffv2
str(stock)
stock$diffV2 <- c(0, diff(stock$V2))
stock$diffV3 <- c(0, diff(stock$V3))
stock$diffV4 <- c(0, diff(stock$V4))
stock$diffV5 <- c(0, diff(stock$V5))
stock$diffV6 <- c(0, diff(stock$V6))
stock$diffV7 <- c(0, diff(stock$V7))
summary(stock)
str(stock)
#Extract two simple random samples with replacement of 1000 and 3000 observations (rows)
sample1 = sample(seq(1,length(stock$V1)),1000,replace = T)
sample2 = sample(seq(1,length(stock$V1)),3000,replace = T)
my_sample = stock[sample1,1]
my_sample
my_sample = stock[sample1,2]
my_sample
head(my_sample)
mean(my_sample)
my_sample = stock[sample1,2]
mean(my_sample)
#Extract two simple random samples with replacement of 1000 and 3000 observations (rows)
sample1 = sample(seq(1,length(stock$V2)),1000,replace = T)
sample2 = sample(seq(1,length(stock$V2)),3000,replace = T)
my_sample = stock[sample1,2]
mean(my_sample)
my_sample = stock[sample1,1]
mean(my_sample)
summary(stock)
my_sample = stock[sample1,8]
mean(my_sample)
max(my_sample)
var(my_sample)
quantile(my_sample,.25)
#Extract two simple random samples with replacement of 1000 and 3000 observations (rows)
sample1 = sample(seq(1,length(stock$V2)),1000,replace = T)
sample2 = sample(seq(1,length(stock$V2)),3000,replace = T)
#Column - 8 (V2)
sampleV2_1 = stock[sample1,8]
mean(sampleV2_1)
sample1 = sample(seq(1,length(stock$V2)),1000,replace = T)
sample2 = sample(seq(1,length(stock$V2)),3000,replace = T)
#Column - 8 (V2)
sampleV2_1 = stock[sample1,8]
mean(sampleV2_1)
max(sampleV2_1)
var(sampleV2_1)
quantile(sampleV2_1,.25)
sampleV2_2 = stock[sample2,8]
mean(sampleV2_2)
max(sampleV2_2)
var(sampleV2_2)
quantile(sampleV2_2,.25)
#Column - 9 (V3)
sampleV3_1 = stock[sample1,9]
mean(sampleV3_1)
max(sampleV3_1)
var(sampleV3_1)
quantile(sampleV3_1,.25)
sampleV3_2 = stock[sample2,9]
mean(sampleV3_2)
max(sampleV3_2)
var(sampleV3_2)
quantile(sampleV3_2,.25)
#Column - 10 (V4)
sampleV4_1 = stock[sample1,10]
mean(sampleV4_1)
max(sampleV4_1)
var(sampleV4_1)
quantile(sampleV4_1,.25)
sampleV4_2 = stock[sample2,10]
mean(sampleV4_2)
max(sampleV4_2)
var(sampleV4_2)
quantile(sampleV4_2,.25)
#Column - 11 (V5)
sampleV5_1 = stock[sample1,11]
mean(sampleV5_1)
max(sampleV5_1)
var(sampleV5_1)
quantile(sampleV5_1,.25)
sampleV5_2 = stock[sample2,11]
mean(sampleV5_2)
max(sampleV5_2)
var(sampleV5_2)
quantile(sampleV5_2,.25)
#Column - 12 (V6)
sampleV6_1 = stock[sample1,12]
mean(sampleV6_1)
max(sampleV6_1)
var(sampleV6_1)
quantile(sampleV6_1,.25)
sampleV6_2 = stock[sample2,12]
mean(sampleV6_2)
max(sampleV6_2)
var(sampleV6_2)
quantile(sampleV6_2,.25)
#Column - 13 (V7)
sampleV7_1 = stock[sample1,13]
mean(sampleV7_1)
max(sampleV7_1)
var(sampleV7_1)
quantile(sampleV7_1,.25)
sampleV7_2 = stock[sample2,13]
mean(sampleV7_2)
max(sampleV7_2)
var(sampleV7_2)
quantile(sampleV7_2,.25)
#Column 8
mean(stock$diffV2)
#Column 8
mean(stock$diffV2)
max(stock$diffV2)
var(stock$diffV2)
quantile(stock$diffV2,.25)
#how much they differ?
abs(mean(sampleV2_1)-mean(stock$diffV2))
abs(max(sampleV2_1)-max(stock$diffV2))
abs(var(sampleV2_1)-var(stock$diffV2))
abs(quantile(sampleV2_1,.25)-quantile(stock$diffV2,.25))
abs(mean(sampleV2_2)-mean(stock$diffV2))
abs(max(sampleV2_2)-max(stock$diffV2))
abs(var(sampleV2_2)-var(stock$diffV2))
abs(quantile(sampleV2_2,.25)-quantile(stock$diffV2,.25))
#Column 9
mean(stock$diffV3)
max(stock$diffV3)
var(stock$diffV3)
quantile(stock$diffV3,.25)
#how much they differ?
abs(mean(sampleV3_1)-mean(stock$diffV3))
abs(max(sampleV3_1)-max(stock$diffV3))
abs(var(sampleV3_1)-var(stock$diffV3))
abs(quantile(sampleV3_1,.25)-quantile(stock$diffV3,.25))
abs(mean(sampleV3_2)-mean(stock$diffV3))
abs(max(sampleV3_2)-max(stock$diffV3))
abs(var(sampleV3_2)-var(stock$diffV3))
abs(quantile(sampleV3_2,.25)-quantile(stock$diffV3,.25))
boxplot(stock$diffV2,
stock$diffV3
,col = 'blue', main = 'House Boxplot', names=c("CA houses","Ohio houses"),ylab = "Prices(in thousands)")
boxplot(stock$V2,
stock$V3,
stock$V4,
stock$V5,
stock$V6,
stock$V7
,col = 'blue', main = 'Boxplot', names=c("Open","High", "Low", "Close", "volume", "adj"))
boxplot(stock$diffV2,
stock$diffV3,
stock$diffV4,
stock$diffV5,
stock$diffV6,
stock$diffV7
,col = 'blue', main = 'Boxplot', names=c("Open","High", "Low", "Close", "volume", "adj"))
hist(stock$V4,breaks=seq(0,3500000,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(stock$diffV4,breaks=seq(0,3500000,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(stock$diffV4,breaks=seq(0,3500,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
#Use R to produce a frequency histogram for Close values. Use intervals of width 2000 beginning at 0
c = as.numeric(stock$V4)
hist(stock$,breaks=seq(0,3500,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(c,breaks=seq(0,3500,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
#Use R to produce a frequency histogram for Close values. Use intervals of width 2000 beginning at 0
stock$c = as.numeric(stock$V4)
hist(stock$c,breaks=seq(0,3500,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(stock$c,breaks=seq(0,10000,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
#Use R to produce a frequency histogram for Close values. Use intervals of width 2000 beginning at 0
stock$c = as.numeric(stock$V4)
hist(stock$c,breaks=seq(0,3500000,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(stock$c,breaks=seq(0,35000,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(stock$c,breaks=seq(0,3500,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(stock$c,breaks=seq(0,20000,by=2000),col='blue',xlab = "Prices",ylab = "Frequency",main = "CA House Plot")
hist(stock$c,breaks=seq(0,20000,by=2000),col='blue',xlab = "Close",ylab = "Frequency",main = "Histogram Plot")
install.packages("caret")
library(caret)
library(rpart.plot)
data_url <- c("http://archive.ics.uci.edu/ml/datasets/Lenses")
download.file(url = data_url, destfile = "lenses.data")
dataSet <- read.csv("lenses.data", sep = ',', header = FALSE)
str(dataSet)
summary(dataSet)
download.file(url = data_url, destfile = "lenses.data")
dataSet <- read.csv("lenses.data", sep = ',', header = FALSE)
str(dataSet)
dataSet <- read.csv("lenses.data", sep = '.', header = FALSE)
str(dataSet)
dataSet <- read.csv("lenses.data", sep = '', header = FALSE)
str(dataSet)
summary(dataSet)
dataSet <- read.csv("lenses.data", sep = ',', header = FALSE)
str(dataSet)
dataSet <- read.csv("lenses.data", header = FALSE)
str(dataSet)
dataSet <- read.csv("lenses.data", sep = '.', header = FALSE)
str(dataSet)
dataSet <- read.csv("lenses.data", sep = '', header = FALSE)
str(dataSet)
lens = read.csv("lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "6"))
y = as.factor(lens)
y = as.factor(lens$6)
lens = read.csv("lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "6"))
str(lens)
y = as.factor(lens$6)
lens = read.csv("lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(lens)
summary(lens)
y = as.factor(lens$Label)
x = lensdata[,1:4]
x = lens[,1:4]
y = as.factor(lens$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=5))
rpart.plot(model)
text(model)
plot(model)
text(model)
rpart.plot(model)
#Information Gain
sum(y==predict(model,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model,x,type="class"))/length(y)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=7))
model1 = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=7))
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=5))
plot(model1)
text(model1)
rpart.plot(model1)
#Information Gain
sum(y==predict(model1,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model1,x,type="class"))/length(y)
lens = read.csv("lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
data_url <- c("http://archive.ics.uci.edu/ml/datasets/Lenses")
download.file(url = data_url, destfile = "lenses.data")
lens = read.csv("lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/2")
data_url <- c("http://archive.ics.uci.edu/ml/datasets/Lenses")
download.file(url = data_url, destfile = "lenses.data")
lens = read.csv("lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/3")
data_url <- c("http://archive.ics.uci.edu/ml/datasets/Lenses")
download.file(url = data_url, destfile = "lenses.data")
lens = read.csv("lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(lens)
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/2")
data = read.csv("apriori_data.csv", header = TRUE);
data$TID <- NULL
library(arules)
write.csv(data, "ItemList.csv", quote = FALSE, row.names = TRUE)
txn = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
basket_rules <- apriori(txn, parameter = list(sup = 0.03, conf = 0.5,target="rules"))
inspect(sort(basket_rules, by = 'lift')[1:15])
itemFrequencyPlot(txn, topN = 5)
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/6")
liver = read.csv("bupa.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "6", "7"))
str(lens)
str(liver)
summary(liver)
x<-data[,1:2]
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 2)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:4]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 2)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:4]
plot(x,pch=19)
fit<-kmeans(x, 2)
x<-data[,1:7]
x<-liver[,1:7]
fit<-kmeans(x, 4)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
liver = read.csv("bupa.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "6", "7"))
str(liver)
summary(liver)
x<-liver[,1:4]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:7]
fit<-kmeans(x, 4)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
x<-liver[,1:4]
fit<-kmeans(x, 4)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
x<-liver[,1:5]
fit<-kmeans(x, 4)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 2)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:4]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:4]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
plot(x,pch=19)
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:4]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 2)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/2")
data = read.csv("apriori_data.csv", header = TRUE);
data$TID <- NULL
library(arules)
ap = read.csv("apriori_data.csv", header = TRUE);
ap$TID <- NULL
library(arules)
write.csv(ap, "ItemList.csv", quote = FALSE, row.names = TRUE)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
basket_rules <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="rules"))
inspect(sort(basket_rules, by = 'lift')[1:15])
itemFrequencyPlot(txn, topN = 5)
itemFrequencyPlot(tramsactions, topN = 5)
itemFrequencyPlot(transactions, topN = 5)
ap = read.csv("apriori_data.csv", header = TRUE);
ap$TID <- NULL
library(arules)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
rules <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="rules"))
inspect(sort(basket_rules, by = 'lift')[1:15])
itemFrequencyPlot(transactions, topN = 5)
ap = read.csv("apriori_data.csv", header = TRUE);
ap$TID <- NULL
library(arules)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
rules <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="rules"))
inspect(sort(basket_rules, by = 'lift')[1:15])
itemFrequencyPlot(transactions, topN = 5)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
x<-data[,1:6]
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/7")
data = read.csv("bupa.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "6", "7"))
str(data)
summary(data)
x<-data[,1:6]
y<-data[,7]
fit<-kmeans(x, 2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
1-sum(knnfit==y)/length(y)
boxplot(stock$diffV2,
stock$diffV3,
stock$diffV4,
stock$diffV5,
stock$diffV6,
stock$diffV7
,col = 'blue', main = 'Boxplot', names=c("Open","High", "Low", "Close", "volume", "adj"))
hist(stock$c,breaks=seq(0,20000,by=2000),col='blue',xlab = "Close",ylab = "Frequency",main = "Histogram Plot")
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/6")
liver = read.csv("bupa.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "6", "7"))
str(liver)
summary(liver)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x, 4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
getwd()
setwd("F:/MSIT/Year 2/Specialization - Data Science/Data Mining/Final exam/2")
ap = read.csv("apriori_data.csv", header = TRUE);
ap$TID <- NULL
library(arules)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
rules <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="rules"))
inspect(sort(basket_rules, by = 'lift')[1:15])
itemFrequencyPlot(transactions, topN = 5)
